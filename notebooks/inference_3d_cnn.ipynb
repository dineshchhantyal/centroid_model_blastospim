{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1645e2",
   "metadata": {},
   "source": [
    "# üîç 3D CNN Inference for Blast Centroid Prediction\n",
    "\n",
    "**Version**: Inference v1.0  \n",
    "**Date**: June 20, 2025  \n",
    "**Objective**: Load trained 3D CNN model and perform centroid predictions on new blast volumetric data  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Inference Configuration\n",
    "\n",
    "This notebook is designed for **fast inference** with:\n",
    "- **Pre-trained model loading** (multiple format support)\n",
    "- **Batch processing** for multiple files\n",
    "- **Memory-efficient data loading** for large 1-2GB files\n",
    "- **Real-time visualization** of predictions\n",
    "- **Export capabilities** for results\n",
    "\n",
    "**Expected Runtime**: Seconds to minutes depending on number of files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43039dba",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "### Import Required Libraries\n",
    "\n",
    "Load all necessary libraries for model inference and data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6044682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: GPU\n",
      "‚úÖ Environment setup completed!\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Configure warnings and logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow warnings\n",
    "\n",
    "\n",
    "# Check device availability\n",
    "device = 'GPU' if tf.config.list_physical_devices('GPU') else 'CPU'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"‚úÖ Environment setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077c5b5",
   "metadata": {},
   "source": [
    "## 2. Model Loading\n",
    "\n",
    "### Load Pre-trained Model\n",
    "\n",
    "Load the trained 3D CNN model from saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422b641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Available trained models:\n",
      "\n",
      "üìÅ Keras format (.keras): 3 found\n",
      "   ‚Ä¢ 3d_cnn_blast_20250620_142339_final.keras\n",
      "   ‚Ä¢ 3d_cnn_blast_20250620_174342_final.keras\n",
      "   ‚Ä¢ 3d_cnn_blast_v220250620_220603_final.keras\n",
      "\n",
      "üìÅ HDF5 format (.h5): 3 found\n",
      "   ‚Ä¢ 3d_cnn_blast_20250620_142339_final.h5\n",
      "   ‚Ä¢ 3d_cnn_blast_v220250620_220603_final.h5\n",
      "   ‚Ä¢ 3d_cnn_blast_20250620_174342_final.h5\n",
      "\n",
      "üìÅ SavedModel format: 2 found\n",
      "   ‚Ä¢ 3d_cnn_blast_20250620_142339_savedmodel\n",
      "   ‚Ä¢ 3d_cnn_blast_20250620_174342_savedmodel\n",
      "\n",
      "üéØ Auto-selected model: 3d_cnn_blast_v220250620_220603_final.keras (keras format)\n",
      "\n",
      "‚è≥ Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 22:25:36.894457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 493 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1c:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n",
      "\n",
      "üìä Model Information:\n",
      "   üìê Input shape: (None, 128, 128, 128, 1)\n",
      "   üìê Output shape: (None, 3)\n",
      "   üßÆ Parameters: 344,771\n",
      "\n",
      "‚ö†Ô∏è  No metadata file found for this model\n",
      "\n",
      "üöÄ Model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# Define model directory\n",
    "models_dir = project_root / \"models\"\n",
    "\n",
    "# List available trained models\n",
    "print(\"üîç Available trained models:\")\n",
    "keras_models = list(models_dir.glob(\"*final.keras\"))\n",
    "h5_models = list(models_dir.glob(\"*final.h5\"))\n",
    "savedmodel_dirs = [d for d in models_dir.glob(\"*savedmodel\") if d.is_dir()]\n",
    "\n",
    "print(f\"\\nüìÅ Keras format (.keras): {len(keras_models)} found\")\n",
    "for model_file in keras_models:\n",
    "    print(f\"   ‚Ä¢ {model_file.name}\")\n",
    "\n",
    "print(f\"\\nüìÅ HDF5 format (.h5): {len(h5_models)} found\")\n",
    "for model_file in h5_models:\n",
    "    print(f\"   ‚Ä¢ {model_file.name}\")\n",
    "\n",
    "print(f\"\\nüìÅ SavedModel format: {len(savedmodel_dirs)} found\")\n",
    "for model_dir in savedmodel_dirs:\n",
    "    print(f\"   ‚Ä¢ {model_dir.name}\")\n",
    "\n",
    "# Auto-select the most recent model (prefer Keras format)\n",
    "if keras_models:\n",
    "    # Sort by modification time and get the most recent\n",
    "    most_recent_model = sorted(keras_models, key=lambda x: x.stat().st_mtime)[-1]\n",
    "    model_format = \"keras\"\n",
    "elif h5_models:\n",
    "    most_recent_model = sorted(h5_models, key=lambda x: x.stat().st_mtime)[-1]\n",
    "    model_format = \"h5\"\n",
    "elif savedmodel_dirs:\n",
    "    most_recent_model = sorted(savedmodel_dirs, key=lambda x: x.stat().st_mtime)[-1]\n",
    "    model_format = \"savedmodel\"\n",
    "else:\n",
    "    raise FileNotFoundError(\"No trained models found! Please run training first.\")\n",
    "\n",
    "print(f\"\\nüéØ Auto-selected model: {most_recent_model.name} ({model_format} format)\")\n",
    "\n",
    "# Load the model\n",
    "print(f\"\\n‚è≥ Loading model...\")\n",
    "try:\n",
    "    if model_format == \"savedmodel\":\n",
    "        model = tf.saved_model.load(str(most_recent_model))\n",
    "        # For SavedModel, we need to get the inference function\n",
    "        infer = model.signatures[\"serving_default\"]\n",
    "        print(f\"‚úÖ SavedModel loaded successfully!\")\n",
    "        use_savedmodel = True\n",
    "    else:\n",
    "        model = tf.keras.models.load_model(str(most_recent_model))\n",
    "        print(f\"‚úÖ Model loaded successfully!\")\n",
    "        use_savedmodel = False\n",
    "        \n",
    "        # Display model information\n",
    "        print(f\"\\nüìä Model Information:\")\n",
    "        print(f\"   üìê Input shape: {model.input_shape}\")\n",
    "        print(f\"   üìê Output shape: {model.output_shape}\")\n",
    "        print(f\"   üßÆ Parameters: {model.count_params():,}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Try to load model metadata if available\n",
    "model_name = most_recent_model.stem.replace(\"_final\", \"\")\n",
    "results_file = models_dir / f\"{model_name}_results.json\"\n",
    "\n",
    "if results_file.exists():\n",
    "    with open(results_file, 'r') as f:\n",
    "        model_metadata = json.load(f)\n",
    "    \n",
    "    print(f\"\\nüìã Model Metadata:\")\n",
    "    print(f\"   üéØ Task: 3D Centroid Regression\")\n",
    "    print(f\"   üìÖ Trained: {model_metadata.get('training_start_time', 'Unknown')[:19]}\")\n",
    "    print(f\"   üìä Test MSE: {model_metadata.get('final_metrics', {}).get('test_mse', 'N/A')}\")\n",
    "    print(f\"   üìä Test R¬≤: {model_metadata.get('final_metrics', {}).get('test_r2_score', 'N/A')}\")\n",
    "    print(f\"   üì¶ Samples trained on: {model_metadata.get('data_info', {}).get('total_samples', 'N/A')}\")\n",
    "else:\n",
    "    model_metadata = None\n",
    "    print(f\"\\n‚ö†Ô∏è  No metadata file found for this model\")\n",
    "\n",
    "print(f\"\\nüöÄ Model ready for inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476a17e",
   "metadata": {},
   "source": [
    "## 3. Data Loading Functions\n",
    "\n",
    "### Preprocessing Functions for Inference\n",
    "\n",
    "Define functions to load and preprocess data for inference (same as training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4cf5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inference functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_volume_for_inference(file_path, target_shape=(128, 128, 128), verbose=True):\n",
    "    \"\"\"\n",
    "    Load a 3D volume for inference with the same preprocessing as training.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Path or str): Path to the volume file\n",
    "        target_shape (tuple): Target shape for resizing (D, H, W)\n",
    "        verbose (bool): Whether to print loading details\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed volume ready for model input\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = Path(file_path)\n",
    "        \n",
    "        if verbose:\n",
    "            file_size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"üìÇ Loading: {file_path.name} ({file_size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Load volume based on file format\n",
    "        if file_path.suffix == '.npy':\n",
    "            volume = np.load(file_path, mmap_mode='r')\n",
    "        elif file_path.suffix == '.npz':\n",
    "            data = np.load(file_path)\n",
    "            # Check for common keys\n",
    "            for key in ['img', 'volume', 'data', 'array']:\n",
    "                if key in data:\n",
    "                    volume = data[key]\n",
    "                    break\n",
    "            else:\n",
    "                volume = data[list(data.keys())[0]]\n",
    "            data.close()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_path.suffix}\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   üìê Original shape: {volume.shape}\")\n",
    "            print(f\"   üî¢ Data type: {volume.dtype}\")\n",
    "        \n",
    "        # Ensure 3D volume\n",
    "        if volume.ndim != 3:\n",
    "            raise ValueError(f\"Expected 3D volume, got {volume.ndim}D\")\n",
    "        \n",
    "        # Resize if needed\n",
    "        if volume.shape != target_shape:\n",
    "            if verbose:\n",
    "                print(f\"   üîÑ Resizing to: {target_shape}\")\n",
    "            \n",
    "            # Aggressive downsampling for large volumes\n",
    "            z_step = max(1, volume.shape[0] // target_shape[0])\n",
    "            y_step = max(1, volume.shape[1] // target_shape[1])\n",
    "            x_step = max(1, volume.shape[2] // target_shape[2])\n",
    "            \n",
    "            # Subsample\n",
    "            volume = volume[::z_step, ::y_step, ::x_step]\n",
    "            volume = np.array(volume, dtype=np.float32)\n",
    "            \n",
    "            # Fine-tune with interpolation if needed\n",
    "            if volume.shape != target_shape:\n",
    "                zoom_factors = [t/s for t, s in zip(target_shape, volume.shape)]\n",
    "                volume = zoom(volume, zoom_factors, order=1)\n",
    "        else:\n",
    "            volume = np.array(volume, dtype=np.float32)\n",
    "        \n",
    "        # Normalize (same as training)\n",
    "        if volume.max() > volume.min():\n",
    "            p1, p99 = np.percentile(volume, [1, 99])\n",
    "            volume = np.clip(volume, p1, p99)\n",
    "            volume = (volume - p1) / (p99 - p1)\n",
    "        else:\n",
    "            volume = np.full_like(volume, 0.5)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   ‚úÖ Preprocessed shape: {volume.shape}\")\n",
    "            print(f\"   üìä Value range: [{volume.min():.3f}, {volume.max():.3f}]\")\n",
    "        \n",
    "        return volume.astype(np.float32)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_centroid(model, volume, use_savedmodel=False):\n",
    "    \"\"\"\n",
    "    Predict centroid coordinates for a single volume.\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded TensorFlow model\n",
    "        volume (np.ndarray): Preprocessed 3D volume\n",
    "        use_savedmodel (bool): Whether using SavedModel format\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results with coordinates\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add batch and channel dimensions\n",
    "        volume_batch = volume[np.newaxis, ..., np.newaxis]  # Shape: (1, D, H, W, 1)\n",
    "        \n",
    "        # Make prediction\n",
    "        if use_savedmodel:\n",
    "            # For SavedModel format\n",
    "            prediction = model(tf.constant(volume_batch, dtype=tf.float32))\n",
    "            prediction = prediction[list(prediction.keys())[0]].numpy()\n",
    "        else:\n",
    "            # For Keras model\n",
    "            prediction = model.predict(volume_batch, verbose=0)\n",
    "        \n",
    "        # Extract coordinates (normalized [0,1])\n",
    "        coords_normalized = prediction[0]  # Remove batch dimension\n",
    "        \n",
    "        # Denormalize coordinates to original volume space\n",
    "        coords_original = np.array([\n",
    "            coords_normalized[0] * 101,    # Z: back to [0, 101]\n",
    "            coords_normalized[1] * 2048,   # Y: back to [0, 2048]\n",
    "            coords_normalized[2] * 2048    # X: back to [0, 2048]\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'coordinates_normalized': coords_normalized,\n",
    "            'coordinates_original': coords_original,\n",
    "            'z': coords_original[0],\n",
    "            'y': coords_original[1],\n",
    "            'x': coords_original[2]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during prediction: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_ground_truth_centroid(data_file_path, labels_dir):\n",
    "    \"\"\"\n",
    "    Load ground truth centroid if available.\n",
    "    \n",
    "    Args:\n",
    "        data_file_path (Path): Path to data file\n",
    "        labels_dir (Path): Directory containing labels\n",
    "    \n",
    "    Returns:\n",
    "        dict or None: Ground truth centroid coordinates\n",
    "    \"\"\"\n",
    "    try:\n",
    "        label_file = labels_dir / f\"label_{data_file_path.stem}\" / \"data\" / \"label.npz\"\n",
    "        if label_file.exists():\n",
    "            label_data = np.load(label_file)\n",
    "            if 'centroid' in label_data:\n",
    "                centroid = label_data['centroid']\n",
    "                label_data.close()\n",
    "                return {\n",
    "                    'coordinates_original': centroid,\n",
    "                    'coordinates_normalized': np.array([\n",
    "                        centroid[0] / 101.0,\n",
    "                        centroid[1] / 2048.0,\n",
    "                        centroid[2] / 2048.0\n",
    "                    ]),\n",
    "                    'z': centroid[0],\n",
    "                    'y': centroid[1],\n",
    "                    'x': centroid[2]\n",
    "                }\n",
    "            label_data.close()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not load ground truth for {data_file_path.name}: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"‚úÖ Inference functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d27ea",
   "metadata": {},
   "source": [
    "## 4. Single File Inference\n",
    "\n",
    "### Test the Model on a Single File\n",
    "\n",
    "Let's test the model on a single blast file to verify it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e209e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Found 4 data files for inference\n",
      "\n",
      "üéØ Testing with file: F1_095.npz\n",
      "\n",
      "‚è≥ Loading and preprocessing volume...\n",
      "üìÇ Loading: F1_095.npz (221.4 MB)\n",
      "   üìê Original shape: (101, 1048, 731)\n",
      "   üî¢ Data type: uint16\n",
      "   üîÑ Resizing to: (128, 128, 128)\n",
      "   ‚úÖ Preprocessed shape: (128, 128, 128)\n",
      "   üìä Value range: [0.000, 1.000]\n",
      "\n",
      "üß† Making prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750472772.376625  996664 service.cc:145] XLA service 0x1553d40032f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750472772.376691  996664 service.cc:153]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2025-06-20 22:26:12.385230: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-20 22:26:12.446919: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error during prediction: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/3151396683.py\", line 25, in <module>\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/2536727787.py\", line 106, in predict_centroid\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 519, in predict\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 217, in one_step_on_data_distributed\n",
      "\n",
      "Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_525]\n",
      "‚ùå Prediction failed!\n",
      "\n",
      "‚úÖ Single file inference test completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 22:26:12.639951: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 272.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-20 22:26:12.642271: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-06-20 22:26:12.642305: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    }
   ],
   "source": [
    "# Define data paths\n",
    "data_root = project_root / \"data\"\n",
    "raw_data_dir = data_root / \"raw\" / \"F1\"\n",
    "labels_dir = data_root / \"labels\" / \"Blast\"\n",
    "\n",
    "# Find available data files\n",
    "data_files = list(raw_data_dir.glob('*.npy')) + list(raw_data_dir.glob('*.npz'))\n",
    "\n",
    "if not data_files:\n",
    "    print(\"‚ùå No data files found for inference!\")\n",
    "else:\n",
    "    print(f\"üìÅ Found {len(data_files)} data files for inference\")\n",
    "    \n",
    "    # Select a test file (you can change this)\n",
    "    test_file = data_files[0]  # Use first file as example\n",
    "    print(f\"\\nüéØ Testing with file: {test_file.name}\")\n",
    "    \n",
    "    # Load and preprocess the volume\n",
    "    print(f\"\\n‚è≥ Loading and preprocessing volume...\")\n",
    "    volume = load_volume_for_inference(test_file, target_shape=(128, 128, 128))\n",
    "    \n",
    "    if volume is not None:\n",
    "        # Make prediction\n",
    "        print(f\"\\nüß† Making prediction...\")\n",
    "        prediction = predict_centroid(model, volume, use_savedmodel)\n",
    "        \n",
    "        if prediction is not None:\n",
    "            print(f\"\\nüéØ PREDICTION RESULTS:\")\n",
    "            print(f\"   üìç Normalized coordinates: [{prediction['coordinates_normalized'][0]:.3f}, {prediction['coordinates_normalized'][1]:.3f}, {prediction['coordinates_normalized'][2]:.3f}]\")\n",
    "            print(f\"   üìç Original coordinates:   [{prediction['z']:.1f}, {prediction['y']:.1f}, {prediction['x']:.1f}]\")\n",
    "            \n",
    "            # Try to load ground truth for comparison\n",
    "            ground_truth = load_ground_truth_centroid(test_file, labels_dir)\n",
    "            \n",
    "            if ground_truth is not None:\n",
    "                print(f\"\\nüìä GROUND TRUTH COMPARISON:\")\n",
    "                print(f\"   ‚úÖ Ground truth:           [{ground_truth['z']:.1f}, {ground_truth['y']:.1f}, {ground_truth['x']:.1f}]\")\n",
    "                \n",
    "                # Calculate error\n",
    "                error = np.linalg.norm(prediction['coordinates_original'] - ground_truth['coordinates_original'])\n",
    "                print(f\"   üìè Euclidean error:        {error:.2f} units\")\n",
    "                \n",
    "                # Per-coordinate errors\n",
    "                z_error = abs(prediction['z'] - ground_truth['z'])\n",
    "                y_error = abs(prediction['y'] - ground_truth['y'])\n",
    "                x_error = abs(prediction['x'] - ground_truth['x'])\n",
    "                \n",
    "                print(f\"   üìè Z-axis error:           {z_error:.2f} units\")\n",
    "                print(f\"   üìè Y-axis error:           {y_error:.2f} units\")\n",
    "                print(f\"   üìè X-axis error:           {x_error:.2f} units\")\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è  No ground truth available for comparison\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"‚ùå Prediction failed!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to load volume!\")\n",
    "\n",
    "print(f\"\\n‚úÖ Single file inference test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56661a5c",
   "metadata": {},
   "source": [
    "## 5. Batch Inference\n",
    "\n",
    "### Process Multiple Files\n",
    "\n",
    "Run inference on multiple files and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec992301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting batch inference...\n",
      "üìÅ Processing up to 10 files\n",
      "üìä Total files to process: 4\n",
      "\n",
      "üìÇ Processing 1/4: F1_095.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 22:26:22.995156: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 272.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-20 22:26:22.996743: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-06-20 22:26:22.996771: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error during prediction: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/3151396683.py\", line 25, in <module>\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/2536727787.py\", line 106, in predict_centroid\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 519, in predict\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 217, in one_step_on_data_distributed\n",
      "\n",
      "Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_525]\n",
      "   ‚ùå Prediction failed\n",
      "\n",
      "üìÇ Processing 2/4: F1_95.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 22:26:24.482568: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 272.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-20 22:26:24.484058: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-06-20 22:26:24.484089: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error during prediction: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/3151396683.py\", line 25, in <module>\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/2536727787.py\", line 106, in predict_centroid\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 519, in predict\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 217, in one_step_on_data_distributed\n",
      "\n",
      "Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_525]\n",
      "   ‚ùå Prediction failed\n",
      "\n",
      "üìÇ Processing 3/4: F1_171.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 22:26:26.447502: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 272.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-20 22:26:26.449114: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-06-20 22:26:26.449141: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error during prediction: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/3151396683.py\", line 25, in <module>\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/2536727787.py\", line 106, in predict_centroid\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 519, in predict\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 217, in one_step_on_data_distributed\n",
      "\n",
      "Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_525]\n",
      "   ‚ùå Prediction failed\n",
      "\n",
      "üìÇ Processing 4/4: F1_160.npz\n",
      "‚ùå Error during prediction: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/3151396683.py\", line 25, in <module>\n",
      "\n",
      "  File \"/tmp/ipykernel_996532/2536727787.py\", line 106, in predict_centroid\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 519, in predict\n",
      "\n",
      "  File \"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 217, in one_step_on_data_distributed\n",
      "\n",
      "Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_525]\n",
      "   ‚ùå Prediction failed\n",
      "\n",
      "============================================================\n",
      "üìä BATCH INFERENCE SUMMARY\n",
      "============================================================\n",
      "‚úÖ Successfully processed: 0/4 files\n",
      "‚è±Ô∏è  Total processing time: 0:00:05.286391\n",
      "‚ö° Average time per file: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 22:26:27.755491: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 272.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-20 22:26:27.756790: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-06-20 22:26:27.756819: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[1,32,128,128,128]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[1,1,128,128,128]{4,3,2,1,0} %bitcast.373, f32[32,1,3,3,3]{4,3,2,1,0} %transpose.22, f32[32]{0} %arg2.3), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv3D\" op_name=\"sequential_1/conv3d_1/convolution\" source_file=\"/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 285212672 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    }
   ],
   "source": [
    "# Configuration for batch inference\n",
    "MAX_FILES = 10  # Process only first N files (set to None for all files)\n",
    "SAVE_RESULTS = True  # Whether to save results to file\n",
    "\n",
    "print(f\"üöÄ Starting batch inference...\")\n",
    "print(f\"üìÅ Processing up to {MAX_FILES if MAX_FILES else 'all'} files\")\n",
    "\n",
    "# Prepare files list\n",
    "files_to_process = data_files[:MAX_FILES] if MAX_FILES else data_files\n",
    "print(f\"üìä Total files to process: {len(files_to_process)}\")\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Process each file\n",
    "for i, data_file in enumerate(files_to_process):\n",
    "    print(f\"\\nüìÇ Processing {i+1}/{len(files_to_process)}: {data_file.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Load volume\n",
    "        volume = load_volume_for_inference(data_file, verbose=False)\n",
    "        \n",
    "        if volume is not None:\n",
    "            # Make prediction\n",
    "            prediction = predict_centroid(model, volume, use_savedmodel)\n",
    "            \n",
    "            if prediction is not None:\n",
    "                # Load ground truth if available\n",
    "                ground_truth = load_ground_truth_centroid(data_file, labels_dir)\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    'file_name': data_file.name,\n",
    "                    'file_path': str(data_file),\n",
    "                    'prediction': {\n",
    "                        'z': float(prediction['z']),\n",
    "                        'y': float(prediction['y']),\n",
    "                        'x': float(prediction['x']),\n",
    "                        'normalized': prediction['coordinates_normalized'].tolist()\n",
    "                    },\n",
    "                    'ground_truth': None,\n",
    "                    'error': None,\n",
    "                    'processing_time': None\n",
    "                }\n",
    "                \n",
    "                if ground_truth is not None:\n",
    "                    result['ground_truth'] = {\n",
    "                        'z': float(ground_truth['z']),\n",
    "                        'y': float(ground_truth['y']),\n",
    "                        'x': float(ground_truth['x']),\n",
    "                        'normalized': ground_truth['coordinates_normalized'].tolist()\n",
    "                    }\n",
    "                    \n",
    "                    # Calculate error\n",
    "                    error = np.linalg.norm(prediction['coordinates_original'] - ground_truth['coordinates_original'])\n",
    "                    result['error'] = {\n",
    "                        'euclidean': float(error),\n",
    "                        'z_error': float(abs(prediction['z'] - ground_truth['z'])),\n",
    "                        'y_error': float(abs(prediction['y'] - ground_truth['y'])),\n",
    "                        'x_error': float(abs(prediction['x'] - ground_truth['x']))\n",
    "                    }\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "                # Print summary\n",
    "                coord_str = f\"[{prediction['z']:.1f}, {prediction['y']:.1f}, {prediction['x']:.1f}]\"\n",
    "                if ground_truth is not None:\n",
    "                    error_str = f\"(error: {error:.1f})\"\n",
    "                    print(f\"   ‚úÖ Predicted: {coord_str} {error_str}\")\n",
    "                else:\n",
    "                    print(f\"   ‚úÖ Predicted: {coord_str}\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå Prediction failed\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Volume loading failed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error processing file: {e}\")\n",
    "        continue\n",
    "\n",
    "# Calculate processing statistics\n",
    "end_time = datetime.now()\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_file = total_time.total_seconds() / len(results) if results else 0\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"üìä BATCH INFERENCE SUMMARY\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"‚úÖ Successfully processed: {len(results)}/{len(files_to_process)} files\")\n",
    "print(f\"‚è±Ô∏è  Total processing time: {total_time}\")\n",
    "print(f\"‚ö° Average time per file: {avg_time_per_file:.2f} seconds\")\n",
    "\n",
    "if results:\n",
    "    # Calculate error statistics if ground truth is available\n",
    "    results_with_gt = [r for r in results if r['ground_truth'] is not None]\n",
    "    \n",
    "    if results_with_gt:\n",
    "        errors = [r['error']['euclidean'] for r in results_with_gt]\n",
    "        print(f\"\\nüìè ERROR STATISTICS (ground truth available for {len(results_with_gt)} files):\")\n",
    "        print(f\"   üìä Mean error: {np.mean(errors):.2f} units\")\n",
    "        print(f\"   üìä Std error:  {np.std(errors):.2f} units\")\n",
    "        print(f\"   üìä Min error:  {np.min(errors):.2f} units\")\n",
    "        print(f\"   üìä Max error:  {np.max(errors):.2f} units\")\n",
    "    \n",
    "    print(f\"\\nüéØ SAMPLE PREDICTIONS:\")\n",
    "    for i, result in enumerate(results[:5]):  # Show first 5\n",
    "        pred = result['prediction']\n",
    "        coord_str = f\"[{pred['z']:.1f}, {pred['y']:.1f}, {pred['x']:.1f}]\"\n",
    "        if result['error']:\n",
    "            error_str = f\" (error: {result['error']['euclidean']:.1f})\"\n",
    "        else:\n",
    "            error_str = \"\"\n",
    "        print(f\"   {i+1}. {result['file_name']}: {coord_str}{error_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35b796",
   "metadata": {},
   "source": [
    "## 6. Results Visualization\n",
    "\n",
    "### Visualize Inference Results\n",
    "\n",
    "Create visualizations of the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1eb146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No results available for visualization\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    # Filter results with ground truth for visualization\n",
    "    results_with_gt = [r for r in results if r['ground_truth'] is not None]\n",
    "    \n",
    "    if results_with_gt:\n",
    "        print(f\"üìä Creating visualizations for {len(results_with_gt)} files with ground truth...\")\n",
    "        \n",
    "        # Extract data for plotting\n",
    "        pred_coords = np.array([[r['prediction']['z'], r['prediction']['y'], r['prediction']['x']] for r in results_with_gt])\n",
    "        true_coords = np.array([[r['ground_truth']['z'], r['ground_truth']['y'], r['ground_truth']['x']] for r in results_with_gt])\n",
    "        errors = np.array([r['error']['euclidean'] for r in results_with_gt])\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('3D CNN Centroid Prediction Results', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Prediction vs Ground Truth for each coordinate\n",
    "        coords = ['Z', 'Y', 'X']\n",
    "        colors = ['red', 'green', 'blue']\n",
    "        \n",
    "        ax = axes[0, 0]\n",
    "        for i, (coord, color) in enumerate(zip(coords, colors)):\n",
    "            ax.scatter(true_coords[:, i], pred_coords[:, i], alpha=0.6, label=f'{coord}-coordinate', color=color)\n",
    "        \n",
    "        # Perfect prediction line\n",
    "        min_val = min(true_coords.min(), pred_coords.min())\n",
    "        max_val = max(true_coords.max(), pred_coords.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect prediction')\n",
    "        \n",
    "        ax.set_xlabel('Ground Truth Coordinates')\n",
    "        ax.set_ylabel('Predicted Coordinates')\n",
    "        ax.set_title('Predicted vs True Coordinates')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Error distribution histogram\n",
    "        ax = axes[0, 1]\n",
    "        ax.hist(errors, bins=min(20, len(errors)//2), alpha=0.7, color='orange', edgecolor='black')\n",
    "        ax.axvline(np.mean(errors), color='red', linestyle='--', label=f'Mean: {np.mean(errors):.1f}')\n",
    "        ax.axvline(np.median(errors), color='blue', linestyle='--', label=f'Median: {np.median(errors):.1f}')\n",
    "        ax.set_xlabel('Euclidean Error (units)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Prediction Error Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Per-coordinate error comparison\n",
    "        ax = axes[1, 0]\n",
    "        coord_errors = np.array([[r['error']['z_error'], r['error']['y_error'], r['error']['x_error']] for r in results_with_gt])\n",
    "        \n",
    "        box_data = [coord_errors[:, i] for i in range(3)]\n",
    "        bp = ax.boxplot(box_data, labels=coords, patch_artist=True)\n",
    "        \n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.6)\n",
    "        \n",
    "        ax.set_ylabel('Absolute Error (units)')\n",
    "        ax.set_title('Per-Coordinate Error Distribution')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Error vs file index (to see if there are patterns)\n",
    "        ax = axes[1, 1]\n",
    "        file_indices = range(len(results_with_gt))\n",
    "        ax.scatter(file_indices, errors, alpha=0.6, color='purple')\n",
    "        ax.axhline(np.mean(errors), color='red', linestyle='--', alpha=0.7, label=f'Mean error: {np.mean(errors):.1f}')\n",
    "        ax.set_xlabel('File Index')\n",
    "        ax.set_ylabel('Euclidean Error (units)')\n",
    "        ax.set_title('Error per File')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        viz_path = project_root / 'visualizations' / f'inference_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png'\n",
    "        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"üìä Visualization saved to: {viz_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  No ground truth data available for visualization\")\n",
    "        \n",
    "        # Create a simple visualization showing predictions only\n",
    "        pred_coords = np.array([[r['prediction']['z'], r['prediction']['y'], r['prediction']['x']] for r in results])\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        \n",
    "        ax.scatter(range(len(results)), pred_coords[:, 0], alpha=0.6, label='Z-coordinate', color='red')\n",
    "        ax.scatter(range(len(results)), pred_coords[:, 1], alpha=0.6, label='Y-coordinate', color='green')\n",
    "        ax.scatter(range(len(results)), pred_coords[:, 2], alpha=0.6, label='X-coordinate', color='blue')\n",
    "        \n",
    "        ax.set_xlabel('File Index')\n",
    "        ax.set_ylabel('Predicted Coordinates')\n",
    "        ax.set_title('Predicted Centroid Coordinates')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        viz_path = project_root / 'visualizations' / f'inference_predictions_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png'\n",
    "        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"üìä Prediction visualization saved to: {viz_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No results available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d1537",
   "metadata": {},
   "source": [
    "## 7. Export Results\n",
    "\n",
    "### Save Results to Files\n",
    "\n",
    "Export the inference results for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b1ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No results to save\n",
      "\n",
      "‚úÖ Inference notebook completed successfully!\n"
     ]
    }
   ],
   "source": [
    "if SAVE_RESULTS and results:\n",
    "    print(f\"üíæ Saving inference results...\")\n",
    "    \n",
    "    # Create timestamp for file naming\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = project_root / \"inference_results\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 1. Save detailed JSON results\n",
    "    json_path = output_dir / f\"inference_results_{timestamp}.json\"\n",
    "    \n",
    "    # Add metadata to results\n",
    "    output_data = {\n",
    "        'metadata': {\n",
    "            'inference_timestamp': timestamp,\n",
    "            'model_file': most_recent_model.name,\n",
    "            'model_format': model_format,\n",
    "            'total_files_processed': len(results),\n",
    "            'files_with_ground_truth': len([r for r in results if r['ground_truth'] is not None]),\n",
    "            'processing_time_seconds': total_time.total_seconds(),\n",
    "            'average_time_per_file': avg_time_per_file\n",
    "        },\n",
    "        'model_metadata': model_metadata,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "    \n",
    "    print(f\"üìÑ JSON results saved to: {json_path}\")\n",
    "    \n",
    "    # 2. Save CSV summary for easy analysis\n",
    "    csv_path = output_dir / f\"inference_summary_{timestamp}.csv\"\n",
    "    \n",
    "    # Create DataFrame\n",
    "    csv_data = []\n",
    "    for result in results:\n",
    "        row = {\n",
    "            'file_name': result['file_name'],\n",
    "            'predicted_z': result['prediction']['z'],\n",
    "            'predicted_y': result['prediction']['y'],\n",
    "            'predicted_x': result['prediction']['x']\n",
    "        }\n",
    "        \n",
    "        if result['ground_truth']:\n",
    "            row.update({\n",
    "                'true_z': result['ground_truth']['z'],\n",
    "                'true_y': result['ground_truth']['y'],\n",
    "                'true_x': result['ground_truth']['x'],\n",
    "                'euclidean_error': result['error']['euclidean'],\n",
    "                'z_error': result['error']['z_error'],\n",
    "                'y_error': result['error']['y_error'],\n",
    "                'x_error': result['error']['x_error']\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                'true_z': None,\n",
    "                'true_y': None,\n",
    "                'true_x': None,\n",
    "                'euclidean_error': None,\n",
    "                'z_error': None,\n",
    "                'y_error': None,\n",
    "                'x_error': None\n",
    "            })\n",
    "        \n",
    "        csv_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"üìä CSV summary saved to: {csv_path}\")\n",
    "    \n",
    "    # 3. Print summary statistics\n",
    "    print(f\"\\nüìã EXPORT SUMMARY:\")\n",
    "    print(f\"   üìÅ Output directory: {output_dir}\")\n",
    "    print(f\"   üìÑ JSON file: {json_path.name}\")\n",
    "    print(f\"   üìä CSV file: {csv_path.name}\")\n",
    "    print(f\"   üìè File sizes:\")\n",
    "    print(f\"      JSON: {json_path.stat().st_size / 1024:.1f} KB\")\n",
    "    print(f\"      CSV:  {csv_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Calculate and display final statistics\n",
    "    results_with_gt = [r for r in results if r['ground_truth'] is not None]\n",
    "    if results_with_gt:\n",
    "        errors = [r['error']['euclidean'] for r in results_with_gt]\n",
    "        print(f\"\\nüìä FINAL PERFORMANCE STATISTICS:\")\n",
    "        print(f\"   üéØ Files with ground truth: {len(results_with_gt)}\")\n",
    "        print(f\"   üìè Mean error: {np.mean(errors):.2f} ¬± {np.std(errors):.2f} units\")\n",
    "        print(f\"   üìè Median error: {np.median(errors):.2f} units\")\n",
    "        print(f\"   üìè Error range: [{np.min(errors):.2f}, {np.max(errors):.2f}] units\")\n",
    "\n",
    "else:\n",
    "    if not SAVE_RESULTS:\n",
    "        print(f\"üíæ Results saving is disabled (SAVE_RESULTS=False)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  No results to save\")\n",
    "\n",
    "print(f\"\\n‚úÖ Inference notebook completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6f176",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Inference Summary\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "1. **Load Pre-trained Models**: Support for multiple formats (.keras, .h5, SavedModel)\n",
    "2. **Single File Inference**: Test model on individual files\n",
    "3. **Batch Processing**: Efficiently process multiple files\n",
    "4. **Ground Truth Comparison**: Compare predictions with known labels\n",
    "5. **Visualization**: Create plots showing prediction accuracy\n",
    "6. **Results Export**: Save results in JSON and CSV formats\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Memory Efficient**: Uses the same preprocessing as training\n",
    "- **Fast Processing**: Optimized for inference speed\n",
    "- **Comprehensive Results**: Detailed error analysis when ground truth is available\n",
    "- **Multiple Output Formats**: JSON for detailed analysis, CSV for spreadsheet use\n",
    "- **Visualization**: Professional plots for presentation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Deploy Model**: Use this notebook as basis for production inference\n",
    "2. **API Development**: Create REST API using the inference functions\n",
    "3. **Real-time Processing**: Adapt for streaming data processing\n",
    "4. **Performance Optimization**: Further optimize for specific hardware\n",
    "\n",
    "---\n",
    "\n",
    "**Model Performance Summary** (when ground truth is available):\n",
    "- Predicts 3D centroid coordinates in blast volumetric data\n",
    "- Coordinates are in original volume space (Z: 0-101, Y: 0-2048, X: 0-2048)\n",
    "- Error metrics include Euclidean distance and per-coordinate errors\n",
    "- Visualization helps identify prediction patterns and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d54d6-8c44-421f-a723-4da88e574310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
