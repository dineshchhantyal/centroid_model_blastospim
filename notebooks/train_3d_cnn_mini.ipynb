{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a96eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU configured: 1 device(s) found\n",
      "✅ Environment setup complete\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Global configuration\n",
    "INPUT_SHAPE = (128, 128, 128, 1)\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 200\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Basic GPU configuration (handles CUDA compatibility issues)\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(f\"✅ GPU configured: {len(gpus)} device(s) found\")\n",
    "    else:\n",
    "        print(\"⚠️  No GPU found - using CPU\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  GPU setup failed: {e} - using CPU fallback\")\n",
    "\n",
    "print(\"✅ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc6bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_volume(file_path, target_shape=(128, 128, 128)):\n",
    "    try:\n",
    "        with np.load(file_path) as data:\n",
    "            # Get volume data\n",
    "            volume = data['img']\n",
    "            \n",
    "            volume = (volume - volume.min()) / (volume.max() - volume.min() + 1e-8)\n",
    "            return volume.astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed: {file_path.name}\")\n",
    "        return None\n",
    "\n",
    "def load_dataset(num_samples=None):\n",
    "    # Paths\n",
    "    \n",
    "    raw_dir = Path('/mnt/home/dchhantyal/centroid_model_blastospim/data/raw/')\n",
    "    labels_dir = Path('/mnt/home/dchhantyal/centroid_model_blastospim/data/labels/Blast')\n",
    "    \n",
    "    # Get data files from all subdirectories\n",
    "    data_files = sorted(list(raw_dir.rglob('*.npz')))\n",
    "    if num_samples:\n",
    "        data_files = data_files[:num_samples]\n",
    "    \n",
    "    print(f\"📦 Processing {len(data_files)} files...\")\n",
    "    \n",
    "    volumes, centroids = [], []\n",
    "    \n",
    "    # Process with threading for I/O\n",
    "    def process_file(file_path):\n",
    "        volume = load_volume(file_path)\n",
    "        if volume is None:\n",
    "            return None, None\n",
    "            \n",
    "        # Load corresponding label\n",
    "        label_file = labels_dir / f\"label_{file_path.stem}\" / \"data\" / \"label.npz\"\n",
    "        try:\n",
    "            with np.load(label_file) as label_data:\n",
    "                centroid = label_data['centroid']\n",
    "                # Normalize centroid [0,1]\n",
    "                norm_centroid = np.array([\n",
    "                    centroid[0], \n",
    "                    centroid[1], \n",
    "                    centroid[2]\n",
    "                ], dtype=np.float32)\n",
    "                print(\"volumne shape \",volume.shape, \" file name:\", file_path.stem)\n",
    "                return volume, norm_centroid\n",
    "        except:\n",
    "            print(file_path, \" loading failed\")\n",
    "            return None, None\n",
    "    \n",
    "    # Parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        results = list(executor.map(process_file, data_files))\n",
    "    \n",
    "    # Collect successful results\n",
    "    for volume, centroid in results:\n",
    "        if volume is not None:\n",
    "            volumes.append(volume)\n",
    "            centroids.append(centroid)\n",
    "    \n",
    "    print(f\"✅ Loaded {len(volumes)} samples successfully\")\n",
    "    return np.array(volumes), np.array(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dabb2a15-e020-451e-90a6-4d6c9e2b983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Loading dataset...\n",
      "📦 Processing 20 files...\n",
      "volumne shape  (91, 2048, 2048)  file name: Blast_001\n",
      "volumne shape  (96, 2048, 2048)  file name: Blast_002\n",
      "volumne shape  (96, 2048, 2048)  file name: Blast_003\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_005\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_008\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_007\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_006\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_004\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_009\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_010\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_011\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_016\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_013\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_015\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_012\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_014\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_019\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_020\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_021\n",
      "volumne shape  (101, 2048, 2048)  file name: Blast_022\n",
      "✅ Loaded 20 samples successfully\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load data \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Add channel dimension for CNN\u001b[39;00m\n\u001b[1;32m      9\u001b[0m X \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "Cell \u001b[0;32mIn[21], line 62\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(num_samples)\u001b[0m\n\u001b[1;32m     59\u001b[0m         centroids\u001b[38;5;241m.\u001b[39mappend(centroid)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(volumes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolumes\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(centroids)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "print(\"🚀 Loading dataset...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Load data \n",
    "X, y = load_dataset(num_samples=20)\n",
    "\n",
    "# Add channel dimension for CNN\n",
    "X = X[..., np.newaxis]\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=VALIDATION_SPLIT, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "loading_time = time.time() - start_time\n",
    "\n",
    "print(f\"✅ Dataset loaded successfully!\")\n",
    "print(f\"📊 Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"📊 Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"⏱️  Loading time: {loading_time:.2f} seconds\")\n",
    "print(f\"💾 Memory usage: {(X.nbytes + y.nbytes) / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223bbfa-6215-47d2-bfee-76eeed7cf2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43df6d1-8eb0-4dd9-a43e-e49daf0f661e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-gpu",
   "language": "python",
   "name": "jupyter-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
